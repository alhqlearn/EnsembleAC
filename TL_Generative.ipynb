{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import os \n",
    "import torch \n",
    "#os.environment['CUDA_VISIBLE_DEVICES'] = 5\n",
    "%env CUDA_VISIBLE_DEVICES=6\n",
    "device = torch.device('cuda:6' if torch.cuda.is_available() else \"cpu\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('./fastai1/')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "hqu7kzBQEKkV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd \n",
    "import numpy as np\n",
    "import threading\n",
    "import random\n",
    "\n",
    "from rdkit import Chem\n",
    "from rdkit.Chem import Draw\n",
    "from rdkit.Chem.Draw import IPythonConsole\n",
    "from rdkit import RDLogger\n",
    "from IPython.display import display,Image, SVG\n",
    "from rdkit.Chem import rdmolops\n",
    "RDLogger.DisableLog('rdApp.*') # switch off RDKit warning messages\n",
    "\n",
    "\n",
    "from fastai import *\n",
    "from fastai.text import *\n",
    "from fastai.vision import *\n",
    "from fastai.imports import *\n",
    "from fastai.callbacks import *\n",
    "\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn.functional as F\n",
    "from sklearn.utils import shuffle\n",
    "from sklearn.model_selection import train_test_split\n",
    "current_path = os.getcwd()\n",
    "print(current_path)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5h0NN2lsx_ew"
   },
   "source": [
    "Set the seed value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9Ock3WMvwIyA",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def random_seed(seed_value, use_cuda):\n",
    "    np.random.seed(seed_value) # cpu vars\n",
    "    torch.manual_seed(seed_value) # cpu  vars\n",
    "    random.seed(seed_value) # Python\n",
    "    if use_cuda:\n",
    "        torch.cuda.manual_seed(seed_value)\n",
    "        torch.cuda.manual_seed_all(seed_value) # gpu vars\n",
    "        torch.backends.cudnn.deterministic = True  #needed\n",
    "        torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "rMiL1lsHzGqz",
    "outputId": "3eb21a70-eb80-4d53-f2b4-39571962a035",
    "tags": []
   },
   "outputs": [],
   "source": [
    "exp_smiles = pd.read_csv('./data/Experimental_Ligands.csv')\n",
    "print('Dataset:', exp_smiles.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "o8Be_xw8EIQ0",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# Create a path to save the results\n",
    "GEN = Path('./results/generative_model')\n",
    "GEN.mkdir(parents=True, exist_ok=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Ofum-GoqEz4l",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sanitize_smiles(smiles, canonical=True, throw_warning=False):\n",
    "    new_smiles = []\n",
    "    for sm in smiles:\n",
    "        try:\n",
    "            if canonical:\n",
    "                new_smiles.append(Chem.MolToSmiles(Chem.MolFromSmiles(sm, sanitize=True)))\n",
    "            else:\n",
    "                new_smiles.append(sm)\n",
    "        except:\n",
    "            if throw_warning:\n",
    "                warnings.warn('Unsanitized SMILES string: ' + sm, UserWarning)\n",
    "            new_smiles.append('')\n",
    "    return new_smiles\n",
    "\n",
    "\n",
    "def canonical_smiles(smiles, sanitize=True, throw_warning=False):\n",
    "    new_smiles = []\n",
    "    for sm in smiles:\n",
    "        try:\n",
    "            mol = Chem.MolFromSmiles(sm, sanitize=sanitize)\n",
    "            new_smiles.append(Chem.MolToSmiles(mol))\n",
    "        except:\n",
    "            if throw_warning:\n",
    "                warnings.warn(sm + ' can not be canonized: invalid '\n",
    "                                   'SMILES string!', UserWarning)\n",
    "            new_smiles.append('')\n",
    "    return new_smiles"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "iU1MTnQhFVpH",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def is_valid(smiles):\n",
    "    mol = Chem.MolFromSmiles(smiles)\n",
    "    if mol is not None and mol.GetNumAtoms()>0:\n",
    "        return smiles\n",
    "\n",
    "def uniqueness_score(mols): return set(mols)\n",
    "\n",
    "def novelty_score(mols,ref_mols):\n",
    "    return set.difference(mols,ref_mols)\n",
    "\n",
    "\n",
    "\n",
    "class SamplingCB(LearnerCallback):\n",
    "\n",
    "    _order=-20 # Needs to run before the recorder\n",
    "    def __init__(self,learn:Learner, objective_mols:Collection=None, num_samples:int=100):\n",
    "        super().__init__(learn)\n",
    "        self.num_samples= num_samples\n",
    "        self.max_size = 100\n",
    "        self.temperature = 1.0\n",
    "        self.objective_mols = objective_mols\n",
    "\n",
    "    def on_train_begin(self,**kwargs):\n",
    "        #self.ref_model = load_ref_model()\n",
    "        self.learn.recorder.add_metric_names(['Valid', 'Unique', 'Novel'])\n",
    "\n",
    "    def on_epoch_being(self,**kwargs):\n",
    "        self.objective_mols = random.sample(objective_mols,self.num_samples)\n",
    "\n",
    "    def sampling(self,text:str='', sep:str=''):\n",
    "        \"Vanilla sampling. Return `text` and the `n_words` that come after\"\n",
    "        m = self.learn\n",
    "        m.model.reset()\n",
    "        v = self.learn.data.train_ds.vocab\n",
    "        v_sz = len(v.itos)\n",
    "        # print(v.itos[v_sz-1])\n",
    "        xb,yb = self.learn.data.one_item(text)\n",
    "        new_idx = []\n",
    "        for _ in range(self.max_size):\n",
    "            res = m.pred_batch(batch=(xb,yb))[0][-1]\n",
    "            if self.temperature != 1.:\n",
    "                res.pow_(1 / self.temperature)\n",
    "            idx = torch.multinomial(res, 1).item()\n",
    "            if idx != v_sz-1:\n",
    "                new_idx.append(idx)\n",
    "                xb = xb.new_tensor([idx])[None]\n",
    "            else:\n",
    "                break\n",
    "        return text + sep + sep.join(v.textify(new_idx, sep=None))\n",
    "\n",
    "    def on_epoch_end(self, last_metrics, **kwargs):\n",
    "        print('Sampling...')\n",
    "        p = [self.sampling().replace('xxbos','').replace('xxeos','').replace('xxunk','').replace('xxpad','') for i in range(0,self.num_samples)]\n",
    "        print('Sample of generated SMILES')\n",
    "        print(p[:5])\n",
    "        val = list(filter(is_valid,p)) # Validity\n",
    "        print(val[0:5])\n",
    "        #sanitized = canonical_smiles(val, sanitize=True, throw_warning=True)\n",
    "        uniq = uniqueness_score(val) # Uniqueness\n",
    "        novel = novelty_score(uniq, self.objective_mols) # Novelty\n",
    "\n",
    "        return add_metrics(last_metrics, [len(val)/self.num_samples, len(uniq)/self.num_samples, len(novel)/self.num_samples])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "lAi7dLnjOFso",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def sampling(model,dt,text:str, n_words:int, temperature:float=1., sep:str=' '):\n",
    "    \"Vanilla sampling. Return `text` and the `n_words` that come after\"\n",
    "    model.model.reset()\n",
    "    v = dt.vocab\n",
    "\n",
    "    xb,yb = dt.one_item(text)\n",
    "    new_idx = []\n",
    "    for _ in range(n_words):\n",
    "        res = model.pred_batch(batch=(xb,yb))[0][-1]\n",
    "\n",
    "        if temperature != 1.:\n",
    "            res.pow_(1 / temperature)\n",
    "        idx = torch.multinomial(res, 1).item()\n",
    "        if idx != len(v.itos)-1:\n",
    "            new_idx.append(idx)\n",
    "            xb = xb.new_tensor([idx])[None]\n",
    "        else:\n",
    "            break\n",
    "    return text + sep + sep.join(v.textify(new_idx, sep=None))\n",
    "\n",
    "\n",
    "\n",
    "def validation(model, dt, sampling_temperatures, iterations, samples, ref, maxsize=100):\n",
    "\n",
    "    '''Vanilla sampling and validation function'''\n",
    "    _validity = np.zeros((iterations, len(sampling_temperatures)))\n",
    "    _novelty = np.zeros((iterations, len(sampling_temperatures)))\n",
    "    _uniqueness = np.zeros((iterations, len(sampling_temperatures)))\n",
    "\n",
    "    for j in range(len(sampling_temperatures)):\n",
    "        temp = sampling_temperatures[j]\n",
    "        print('Temperatures = {}'.format(temp))\n",
    "        for i in range(iterations):\n",
    "            print('Starting iteration {}'.format(i))\n",
    "            p = [sampling(model, dt, text='', n_words=maxsize, sep='', temperature=temp).replace(PAD, '').replace(BOS, '').replace(EOS, '').replace(UNK, '') for i in range(0, samples)]\n",
    "            mols = list(filter(is_valid, p))  # Valid\n",
    "            #sanitized = canonical_smiles(mols, sanitize=True, throw_warning=True)\n",
    "            unq_mols = uniqueness_score(mols)  # Uniqueness # Unique\n",
    "            novel_mols = novelty_score(unq_mols, ref)  # Novel\n",
    "\n",
    "            _novelty[i, j] = len(novel_mols) / samples * 100\n",
    "            _uniqueness[i, j] = len(unq_mols) / samples * 100\n",
    "            _validity[i, j] = len(mols) / samples * 100\n",
    "\n",
    "        print('Iteration {} ended'.format(i))\n",
    "    print('----------------------------------')\n",
    "    return _validity, _novelty, _uniqueness, mols, unq_mols, novel_mols\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BD0p1ccHF1WQ"
   },
   "source": [
    "### Data pre-processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "_r2ueR98yiBw"
   },
   "source": [
    "Define a custom tokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ypSUkZEcF8cY",
    "tags": []
   },
   "outputs": [],
   "source": [
    "class MolTokenizer(BaseTokenizer):\n",
    "    ''' Atom-level tokenizer. Splits molecules into individual atoms and special environments.\n",
    "    A special environment is defined by any elements inside square brackets (e.g., [nH])\n",
    "    '''\n",
    "    def __init__(self, lang:str):\n",
    "        pass\n",
    "    \n",
    "    def tokenizer(self, t:str) -> List[str]:\n",
    "        assert type(t) == str\n",
    "        pat = '(\\[.*?\\])'  # Find special environments (e.g., [CH],[NH] etc)\n",
    "        tokens = []\n",
    "        t = t.replace('Br', 'L').replace('Cl', 'X')  # Replace halogens\n",
    "        atom_list = re.split(pat, t)\n",
    "        for s in atom_list:\n",
    "            if s.startswith('['):\n",
    "                tokens.append(s)\n",
    "            else:\n",
    "                tokens += [x for x in list(s)]\n",
    "        tokens = [x.replace('L', 'Br').replace('X', 'Cl') for x in tokens]  # Decode halogens\n",
    "        return [BOS] + tokens + [EOS]  # + [PAD for i in range(133-len(tokens))]\n",
    "\n",
    "class Create_Vocab(object):\n",
    "    '''Tokenize and create vocabulary of atoms in SMILES strings'''\n",
    "    def __init__(self, smiles):\n",
    "        self.smiles = smiles\n",
    "\n",
    "    def tokenize(self):\n",
    "        k = MolTokenizer\n",
    "        tok = Tokenizer(k, pre_rules=[], post_rules=[])\n",
    "        tokens = tok.process_all(self.smiles)\n",
    "\n",
    "        unique_tokens = [UNK, PAD] + sorted(list({y for x in tokens for y in x}))\n",
    "        vocab = Vocab(itos=unique_tokens)\n",
    "\n",
    "        return unique_tokens, vocab\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wg4PxybdHkoW"
   },
   "source": [
    "#### SMILES augmentation for language model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "79f-hUKIJUph",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def randomize_smiles(smiles):\n",
    "    m = Chem.MolFromSmiles(smiles)\n",
    "    ans = list(range(m.GetNumAtoms()))\n",
    "    np.random.shuffle(ans)\n",
    "    nm = Chem.RenumberAtoms(m,ans)\n",
    "    return Chem.MolToSmiles(nm, canonical=False, isomericSmiles=True, kekuleSmiles=False)\n",
    "\n",
    "def lm_smiles_augmentation(df, N_rounds):\n",
    "\n",
    "    dist_aug = {col_name: [] for col_name in df}\n",
    "\n",
    "    for i in range(df.shape[0]):\n",
    "        for j in range(N_rounds):\n",
    "            dist_aug['smiles'].append(randomize_smiles(df.iloc[i].smiles))\n",
    "    df_aug = pd.DataFrame.from_dict(dist_aug)\n",
    "    df_aug = df_aug.append(df, ignore_index=True)\n",
    "    return df_aug.drop_duplicates('smiles')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ToGJrhAYzlmB"
   },
   "source": [
    "The randomized SMILES are used for data augmentation. The number of augmented SMILES can be passed an arguement to the lm_smiles_augmentation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "kV675JIbJYTf",
    "outputId": "4e3b0c21-dbed-4dac-cf29-0c94224a0b5d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "exp_smiles_aug = lm_smiles_augmentation(exp_smiles, 200)\n",
    "print(len(exp_smiles_aug))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JLXiL3931RTA"
   },
   "source": [
    "Create a text databunch for language modeling:\n",
    "\n",
    "- It takes SMILES as input\n",
    "- Pass the custom tokenizer defined in the previous step\n",
    "- Specify the column containing text data\n",
    "- Define the batch size according to the GPU memory available"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "YP516btCIBW3",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "vocab_list = Create_Vocab(list(exp_smiles_aug.smiles))\n",
    "unique_tokens,vocab = vocab_list.tokenize()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WP-F6xwFIPxo",
    "outputId": "792352c7-64f7-4a88-e634-b4cb6acccbe4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "tokenizer = Tokenizer(MolTokenizer,pre_rules=[],post_rules=[],special_cases=[PAD,BOS,EOS,UNK])\n",
    "processors = [TokenizeProcessor(tokenizer=tokenizer, mark_fields=False,include_bos=False), NumericalizeProcessor(vocab=vocab)]\n",
    "src = (TextList.from_df(exp_smiles_aug, path=GEN, cols='smiles', processor=processors).split_by_rand_pct(0.10).label_for_lm())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "MFPLXUwYIq3N",
    "outputId": "460e6667-02d0-4b8c-832f-24fa7c529f45",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "data_fn = src.databunch()\n",
    "data_fn.show_batch()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5W2T96iqJ7o4"
   },
   "source": [
    "## Fine-tuning the target task language model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LI-VM3emJ9T_"
   },
   "source": [
    "Load the pre-trained weights and vocabulary"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "6cDGfqybJF-9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pretrained_model_path = Path('./pre_trained_model_checkpoint/')\n",
    "pretrained_fnames = ['pre_trained_wt', 'pre_trained_vocab']\n",
    "fnames = [pretrained_model_path/f'{fn}.{ext}' for fn,ext in zip(pretrained_fnames, ['pth', 'pkl'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yTtO8YE1D9ct",
    "outputId": "36ad15e3-9518-49a3-aa30-fb9af66bc27c",
    "tags": []
   },
   "outputs": [],
   "source": [
    "#reference dataset\n",
    "smiles_ref = canonical_smiles(list(set(exp_smiles.smiles)), sanitize=True, throw_warning=True)\n",
    "print(len(smiles_ref))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "gJz6g8lZl9UZ",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "learn_fn = language_model_learner(data_fn, AWD_LSTM, pretrained=False, drop_mult=0.8, metrics=[accuracy, error_rate], callback_fns=[partial(CSVLogger,append=True)]).load_pretrained(*fnames)\n",
    "learn_fn.freeze()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YcgzpCFTl9Vi",
    "outputId": "02915f8c-c826-464a-9ebb-02944a95d148",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "learn_fn.fit_one_cycle(5, 1e-1, moms=(0.8,0.7), callbacks=[SamplingCB(learn_fn, num_samples=5, objective_mols=smiles_ref),\n",
    "                                   SaveModelCallback(learn_fn, every='improvement',monitor='accuracy', name='bestmodel')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hhv5swW8mcxF",
    "outputId": "9ef1aea4-4c6e-4e26-8edf-69dd660de257",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "learn_fn.freeze_to(-2)\n",
    "\n",
    "learn_fn.fit_one_cycle(6, 1e-2, moms=(0.8,0.7), callbacks=[SamplingCB(learn_fn, num_samples=5, objective_mols=smiles_ref),\n",
    "                                  SaveModelCallback(learn_fn, every='improvement', monitor='accuracy', name='bestmodel')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "JBi9M3mwmczD",
    "outputId": "3f9a09c1-f8a3-4aed-8c73-1f0562266ade",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "learn_fn.unfreeze()\n",
    "\n",
    "learn_fn.fit_one_cycle(6, 1e-3, moms=(0.8,0.7), callbacks=[SamplingCB(learn_fn, num_samples=100, objective_mols=smiles_ref),\n",
    "                                   SaveModelCallback(learn_fn, every='improvement',\n",
    "                                                     monitor='accuracy', name='bestmodel')])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IQYJeAJaK4O4"
   },
   "source": [
    "Save the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "UfLgcu4-RypP",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn_fn.save_encoder('finetuned_encoder')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "aMAlF_tBLWG-"
   },
   "source": [
    "#### Validate the fine-tuned model in terms of validity, uniqueness, and novelty"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yZCHnUA8JrjN",
    "outputId": "d9ad0d35-0281-473c-fdf6-c8b08488f0a9",
    "tags": []
   },
   "outputs": [],
   "source": [
    "learn_fn.validate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampling_temperatures = [0.2,  0.6,  0.8, 1.0, 1.2, 1.4, 1.6, 1.8, 2.0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "v3eFE7BxaNNp",
    "outputId": "a64bdbe7-b4fa-4297-b5aa-c1895b90a2e2",
    "tags": []
   },
   "outputs": [],
   "source": [
    "random_seed(1234, True)\n",
    "\n",
    "validity, novelty, uniqueness, mols, unq_mols, novel_mols = validation(learn_fn, data_fn, sampling_temperatures, 1, 500, ref=smiles_ref)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "mkjWeM2oa3Fg",
    "tags": []
   },
   "outputs": [],
   "source": [
    "val_df = pd.DataFrame(validity, columns=['Temp_{}'.format(i) for i in sampling_temperatures])\n",
    "nov_df = pd.DataFrame(novelty, columns=['Temp_{}'.format(i) for i in sampling_temperatures])\n",
    "unq_df = pd.DataFrame(uniqueness, columns=['Temp_{}'.format(i) for i in sampling_temperatures])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "26080LtLwV-T",
    "outputId": "8ad57043-85ad-4cb3-d96c-e4a75301fd50",
    "tags": []
   },
   "outputs": [],
   "source": [
    "len(mols), len(unq_mols), len(novel_mols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "DBZ1yhQJuD3J",
    "tags": []
   },
   "outputs": [],
   "source": [
    "pd.Series(list(novel_mols)).to_csv(\"./results/generative_model/Generated_Ligands.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [
    "k_KzxmBtfyK4",
    "u1sNSKp5FPg6",
    "5W2T96iqJ7o4",
    "QQ8Yzez019XQ",
    "8gfWmV_nAOED",
    "AhWjHU00Gn7y",
    "UfeuD_WV7ym_",
    "EjrmpUk_2NBZ",
    "Io3084tI47BS",
    "BTKXd0qg3agN",
    "oJY_XbQhVw7G",
    "MDZqmiKPVv5m"
   ],
   "gpuType": "T4",
   "provenance": []
  },
  "gpuClass": "standard",
  "kernelspec": {
   "display_name": "re-explore",
   "language": "python",
   "name": "re-explore"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  },
  "toc-autonumbering": false,
  "toc-showcode": false,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
